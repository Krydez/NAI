"""
Program do detekcji gest√≥w d≈Çoni z wykorzystaniem OpenCV i cvzone.
cvzone wykorzystuje MediaPipe do detekcji punkt√≥w charakterystycznych d≈Çoni.

Obs≈Çuguje 4 gesty palcami:
- 2 palce - play/pause
- 3 palce - nastƒôpna piosenka
- 4 palce - poprzednia piosenka
- 5 palc√≥w - zrzut ekranu

pip:

pip install opencv-python mediapipe==0.10.9 cvzone pyautogui pillow

Autorzy: Kacper Olejnik, Hubert J√≥≈ºwiak
"""

import cv2
from cvzone.HandTrackingModule import HandDetector
import pyautogui
import time
from datetime import datetime
import os

class GestureDetector:
    def __init__(self):
        # Inicjalizacja detektora d≈Çoni z cvzone
        self.detector = HandDetector(detectionCon=0.7, maxHands=1)
        
        # Op√≥≈∫nienie miƒôdzy akcjami (aby uniknƒÖƒá wielokrotnego wykonania)
        self.last_action_time = 0
        self.action_cooldown = 1.5  # sekundy
        
        # Folder na zrzuty ekranu
        self.screenshots_folder = "screenshots"
        if not os.path.exists(self.screenshots_folder):
            os.makedirs(self.screenshots_folder)
    
    def perform_action(self, finger_count):
        """
        Wykonuje akcjƒô na podstawie liczby palc√≥w
        """
        current_time = time.time()
        
        # Sprawdzenie czy minƒÖ≈Ç czas cooldown
        if current_time - self.last_action_time < self.action_cooldown:
            return None
        
        action = None
        
        if finger_count == 2:
            # Play/Pauza (u≈ºywamy playpause - standardowy klawisz multimedialny)
            pyautogui.press('playpause')
            action = "‚èØÔ∏è Play/Pauza"
            
        elif finger_count == 3:
            # Nastƒôpna piosenka
            pyautogui.press('nexttrack')
            action = "‚è≠Ô∏è Nastƒôpna piosenka"
            
        elif finger_count == 4:
            # Poprzednia piosenka
            pyautogui.press('prevtrack')
            action = "‚èÆÔ∏è Poprzednia piosenka"
            
        elif finger_count == 5:
            # Zrzut ekranu
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            screenshot_path = os.path.join(self.screenshots_folder, f"screenshot_{timestamp}.png")
            screenshot = pyautogui.screenshot()
            screenshot.save(screenshot_path)
            action = f"üì∏ Zrzut ekranu: {screenshot_path}"
        
        if action:
            self.last_action_time = current_time
            print(f"[{datetime.now().strftime('%H:%M:%S')}] {action}")
        
        return action
    
    def run(self):
        """
        G≈Ç√≥wna pƒôtla programu
        """
        print("üîß Inicjalizacja kamery...")
        # Inicjalizacja kamery (0 = domy≈õlna kamera)
        cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # U≈ºyj DirectShow na Windows
        
        # Ustawienie rozdzielczo≈õci dla Logitech C920
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        if not cap.isOpened():
            print("‚ùå Nie mo≈ºna otworzyƒá kamery!")
            print("‚ö†Ô∏è Sprawd≈∫ czy kamera jest pod≈ÇƒÖczona i dostƒôpna")
            return
        
        print("üé• Kamera uruchomiona")
        print("üëã Program detekcji gest√≥w - gotowy!")
        print("\nGesty:")
        print("  2 palce (‚úåÔ∏è)  - Play/Pauza")
        print("  3 palce (ü§ü) - Nastƒôpna piosenka")
        print("  4 palce (üññ) - Poprzednia piosenka")
        print("  5 palc√≥w (üñêÔ∏è) - Zrzut ekranu")
        print("\nNaci≈õnij 'q' aby zako≈Ñczyƒá\n")
        
        current_action = None
        
        while True:
            success, frame = cap.read()
            if not success:
                print("‚ùå Nie mo≈ºna odczytaƒá klatki z kamery")
                break
            
            # Odbicie lustrzane dla lepszego UX
            frame = cv2.flip(frame, 1)
            
            # Detekcja d≈Çoni
            hands, frame = self.detector.findHands(frame)
            
            finger_count = 0
            
            # Je≈õli wykryto d≈Ço≈Ñ
            if hands:
                hand = hands[0]  # Pierwsza d≈Ço≈Ñ
                fingers = self.detector.fingersUp(hand)  # Lista [kciuk, wskazujƒÖcy, ≈õrodkowy, serdeczny, ma≈Çy]
                
                # Liczymy wyprostowane palce
                finger_count = fingers.count(1)
                
                # Wykonanie akcji (tylko dla 2-5 palc√≥w)
                if 2 <= finger_count <= 5:
                    action = self.perform_action(finger_count)
                    if action:
                        current_action = action
            
            # Wy≈õwietlanie informacji na ekranie
            cv2.putText(frame, f"Palce: {finger_count}", (10, 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            if current_action:
                # Usu≈Ñ emoji z wy≈õwietlania (mogƒÖ powodowaƒá b≈Çƒôdy w cv2.putText)
                display_action = current_action.replace("üì∏", "").replace("‚èØÔ∏è", "").replace("‚è≠Ô∏è", "").replace("‚èÆÔ∏è", "").strip()
                cv2.putText(frame, f"Akcja: {display_action}", (10, 100),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            
            # Instrukcje
            cv2.putText(frame, "Nacisnij 'q' aby zakonczyc", (10, frame.shape[0] - 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
            
            # Wy≈õwietlanie obrazu
            cv2.imshow('Detekcja Gestow', frame)
            
            # Wyj≈õcie z programu
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        # SprzƒÖtanie
        cap.release()
        cv2.destroyAllWindows()
        print("\n‚úÖ Program zako≈Ñczony")


if __name__ == "__main__":
    detector = GestureDetector()
    detector.run()
